{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407be414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import socket\n",
    "from sys import argv\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "from blobclient import upload_to_blob\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "path = argv\n",
    "\n",
    "import urllib3\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "\n",
    "class Model_predic_reconv:\n",
    "    \n",
    "\n",
    "    hostname = socket.gethostname()\n",
    "\n",
    "    ##### Inference Image Preprocessing #######\n",
    "\n",
    "    image_size = 300\n",
    "    image_mean = np.array([127, 127, 127])  # RGB layout\n",
    "    image_std = 128.0\n",
    "    \n",
    "    \n",
    "\n",
    "    def resize(self, image, boxes, labels):\n",
    "        \"\"\"\n",
    "            Resize image to a fixed size\n",
    "        \"\"\"\n",
    "    \n",
    "        \n",
    "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        \n",
    "        \n",
    "      \n",
    "        return image, boxes, labels\n",
    "   \n",
    "\n",
    "\n",
    "    def subtract_means(self, image, boxes, labels):\n",
    "        \"\"\"\n",
    "            subtract mean value from the image to normalize it\n",
    "        \"\"\"\n",
    "        mean = np.array(self.image_mean, dtype=np.float32)\n",
    "\n",
    "        image = image.astype(np.float32)\n",
    "        image -= mean\n",
    "        return image.astype(np.float32), boxes, labels\n",
    "\n",
    "    def misc(self, image, boxes, labels):\n",
    "        \"\"\"\n",
    "            Normalize image\n",
    "        \"\"\"\n",
    "        # print('inside misc')\n",
    "        image = image / self.image_std\n",
    "        return image, None, None\n",
    "\n",
    "    def to_tensor(self, image, boxes, labels):\n",
    "        \"\"\"\n",
    "            convert Image(numpy) to Tensor\n",
    "        \"\"\"\n",
    "        # print('inside to_tensor')\n",
    "        return torch.from_numpy(image.astype(np.float32)).permute(2, 0, 1), boxes, labels\n",
    "\n",
    "    def get_infer_transformed(self, image, boxes, labels, infer_transforms):\n",
    "\n",
    "       \n",
    "        for t in infer_transforms:\n",
    "            image, boxes, labels = t(image, boxes, labels)\n",
    "\n",
    "        return image\n",
    "\n",
    "    #############################################\n",
    "\n",
    "    def read_img(self, img_url):\n",
    "        \"\"\"\n",
    "            read image using cv2 and convert from BGR to RGB\n",
    "        \"\"\"\n",
    "      \n",
    "        img = http.request('GET', img_url).data\n",
    "        img = np.array(Image.open(io.BytesIO(img)).convert('RGB')) \n",
    "\n",
    "        return img\n",
    "\n",
    "    def sequential_batch_train(self, img_name, model_var, voc_txt_path,md_name):\n",
    "        image_name = img_name\n",
    "        dict_sequential ={}\n",
    "\n",
    "        if md_name == 'Big Object Model':\n",
    "            print('\\n{} is running for object detection'.format(md_name))   \n",
    "        elif md_name == 'Small Object Model':\n",
    "            print('\\n{} is running for object detection'.format(md_name))\n",
    "        elif md_name == 'Lable model':\n",
    "            print('\\n{} is running for object detection'.format(md_name))\n",
    "            \n",
    "\n",
    "        df_list = []\n",
    "\n",
    "        combined_lst = self.Predict(image_name, model_var, voc_txt_path)\n",
    "#         dict_sequential = {md_name:combined_lst}\n",
    "\n",
    "      \n",
    "        return combined_lst\n",
    "    \n",
    "\n",
    "    def Predict(self,img_name, model_var, voc_txt_path):\n",
    "#         dict_predict ={}\n",
    "        list_put_all_details = []\n",
    "        mAP_list=[]\n",
    "        model = model_var\n",
    "        list_image = []\n",
    "        s = 0\n",
    "        v = 0\n",
    "        temp_store = []\n",
    "        img_list = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            orig_image = self.read_img(img_name)\n",
    "            img_list.append(orig_image)\n",
    "\n",
    "            image_size = 300\n",
    "            image_mean = np.array([127, 127, 127])  # RGB layout\n",
    "            image_std = 128.0\n",
    "            infer_transforms = [self.resize, self.subtract_means, self.misc, self.to_tensor]\n",
    "            class_names = [name.strip() for name in open(voc_txt_path).readlines()]\n",
    "            actual_label_list = []\n",
    "            pred_label = None\n",
    "            probs = None\n",
    "            xmin = None\n",
    "            ymin = None\n",
    "            xmax = None\n",
    "            ymax = None\n",
    "            pred_label_list = []\n",
    "            image_name_list = []\n",
    "            height, width, _ = orig_image.shape\n",
    "            image = self.get_infer_transformed(orig_image, None, None, infer_transforms)\n",
    "            images = image.unsqueeze(0)\n",
    "            t1 = time.time()\n",
    "            all_out = model.forward(images)\n",
    "            list_image.append(all_out)\n",
    "            bx = all_out[:, :4]  # get boxes\n",
    "            lb = all_out[:, 4]  # get labels\n",
    "            conf = all_out[:, 5]  # get probabilities\n",
    "\n",
    "            bx[:, 0] *= width\n",
    "            bx[:, 1] *= height\n",
    "            bx[:, 2] *= width\n",
    "            bx[:, 3] *= height\n",
    "\n",
    "            if bx[0, 0].item() <= -999:\n",
    "\n",
    "                empty_l = [\"BACKGROUND\", 0.0, 0, 0, 0, 0]\n",
    "\n",
    "                pred_label_list.append('NO_DETECTION')\n",
    "            else:\n",
    "\n",
    "               \n",
    "\n",
    "                v += 1\n",
    "                for kj in range(bx.shape[0]):\n",
    "                    box = bx[kj, :]\n",
    "                    labels = lb[kj]\n",
    "                    probs = conf[kj]\n",
    "                    probs = round((probs.detach().item())*100,3)\n",
    "\n",
    "                    xmin, ymin, xmax, ymax = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "\n",
    "                    pred_label = class_names[int(labels.item())]\n",
    "\n",
    "                    mAP_list= [img_name, pred_label, probs,xmin, ymin, xmax, ymax]\n",
    "\n",
    "                    temp_store.append([ pred_label,probs, xmin, ymin, xmax, ymax])\n",
    "              \n",
    "            df = pd.DataFrame(temp_store,columns=['location_code','probs', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "            \n",
    "\n",
    "\n",
    "        keys = ['location_code','probs', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "\n",
    "        combined_lst = []\n",
    "        \n",
    "        for sub_list in temp_store:\n",
    "            dict_predict={}\n",
    "            if (len(sub_list) != 0):\n",
    "                for key_name, val in zip(keys, sub_list):\n",
    "                    dict_predict[key_name] = val\n",
    "                combined_lst.append(dict_predict)\n",
    "            \n",
    "            else:\n",
    "                combined_lst=[]\n",
    "        test_run = drawBoundingBox(orig_image,df)\n",
    "        \n",
    "        filename = str(img_name).split('/')[-1]\n",
    "        cv2.imwrite(filename, test_run)\n",
    "        with Image.open(filename) as img:\n",
    "            buf = io.BytesIO()                        \n",
    "            img.convert('RGB').save(buf, format=\"png\") \n",
    "            img_link = upload_to_blob(filename,buf.getvalue())\n",
    "\n",
    "        return combined_lst\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "def driver(full_img_list, model_path, voc_txt_path, model_path_fr, voc_txt_path_fr,location_model,location_txt):\n",
    "   \n",
    "    \n",
    "\n",
    "    full_img_list = full_img_list\n",
    "    \n",
    "    \n",
    "    Model_predic_reconv.location_model = location_model\n",
    "    Model_predic_reconv.location_txt = location_txt\n",
    "\n",
    "    Model_predic_reconv.model_path = model_path\n",
    "    Model_predic_reconv.voc_txt_path = voc_txt_path\n",
    "\n",
    "    Model_predic_reconv.model_path_fr = model_path_fr\n",
    "    Model_predic_reconv.voc_txt_path_fr = voc_txt_path_fr\n",
    "\n",
    "    b_m = 'Big Object Model'\n",
    "    s_m = 'Small Object Model'\n",
    "    l_m = 'Lable model'\n",
    "    \n",
    "    mpc = Model_predic_reconv()\n",
    "    t1 = time.perf_counter()\n",
    "   \n",
    "    \n",
    "    #loading the models\n",
    "    \n",
    "    var_exists = 'big_obj_model' in locals() or 'big_obj_model' in globals()\n",
    "    t0 = time.time()\n",
    "    if not (var_exists):\n",
    "        big_obj_model = torch.jit.load(Model_predic_reconv.model_path)\n",
    "     \n",
    "    _t0 = time.time()\n",
    "    var_exists_2 = 'small_obj_model' in locals() or 'small_obj_model' in globals()\n",
    "    if not (var_exists_2):\n",
    "        small_obj_model = torch.jit.load(Model_predic_reconv.model_path_fr)\n",
    "        \n",
    "    _t1 = time.time()\n",
    "    var_exists_3 = 'lable_model' in locals() or 'lable_model' in globals()\n",
    "    if not (var_exists_2):\n",
    "        lable_model = torch.jit.load(Model_predic_reconv.location_model)\n",
    "       \n",
    "           \n",
    "    output_file_name = \"{}_Model_predicted_raw_annotated_file.jpg\"\n",
    "    driver_dict = {}\n",
    "    dict_sequential={}\n",
    "    output_lst =[]\n",
    "    ordered_dict ={}\n",
    "    \n",
    "    \n",
    "#     model_lbl = [l_m, b_m, s_m]\n",
    "\n",
    "    for img_name in full_img_list:\n",
    "        print('img_name',img_name)\n",
    "        image_name= img_name.split(\"/\")[-1]\n",
    "       \n",
    "        final_lst = []\n",
    "        lable_dict = {}\n",
    "        sublocation_dict ={}\n",
    "        \n",
    "        \n",
    "        tuples_of_model = [(img_name,big_obj_model,Model_predic_reconv.voc_txt_path,b_m),\n",
    "                           (img_name,small_obj_model, Model_predic_reconv.voc_txt_path_fr,s_m)]\n",
    "        \n",
    "        \n",
    "        lable_tuple = (img_name,lable_model, Model_predic_reconv.location_txt,l_m)\n",
    "        lable_dict['Location']= mpc.sequential_batch_train(*lable_tuple)[0]\n",
    "        \n",
    "        for double in tuples_of_model:\n",
    "            combined_lst = mpc.sequential_batch_train(*double)\n",
    "           \n",
    "            final_lst.append(combined_lst)\n",
    "        \n",
    "        sublocation_dict['Sublocation'] = [j for i in final_lst for j in i]\n",
    "        \n",
    "        lable_dict['Location'].update(sublocation_dict)\n",
    "        driver_dict['fileurl']=img_name \n",
    "        driver_dict['img_name']=image_name\n",
    "        \n",
    "        driver_dict.update(lable_dict)\n",
    "        \n",
    "        myorder = ['fileurl', 'img_name', 'Location']\n",
    "\n",
    "        \n",
    "\n",
    "        ordered = OrderedDict()\n",
    "        for k in myorder:\n",
    "            ordered[k] = driver_dict[k]\n",
    "        \n",
    "        \n",
    "        print('ordered',ordered)\n",
    "        print(\"Updated_dict\",driver_dict)\n",
    "        ordered_dict = dict(ordered)\n",
    "        output_lst.append(ordered_dict)\n",
    "    print('output_lst',output_lst)\n",
    "\n",
    "    t2 = time.perf_counter()   \n",
    "    return output_lst\n",
    "\n",
    "def drawBoundingBox(image,df):\n",
    "#     df_list = []\n",
    "    for box in df.index:\n",
    "        #x1,y1,x2,y2 = (box['topleft']['x'],box['topleft']['y'],box['bottomright']['x'],box['bottomright']['y'])\n",
    "        x1,x2,y1,y2 = df['xmin'][box], df['xmax'][box], df['ymin'][box], df['ymax'][box]\n",
    "\n",
    "        # print(conf)\n",
    "        label = df['location_code'][box]\n",
    "        conf = df['probs'][box]\n",
    "        # if conf < predictThresh:\n",
    "        #     continue\n",
    "\n",
    "        cv2.rectangle(image,(x1,y1),(x2,y2),(0,255,0),6)\n",
    "        labelSize=cv2.getTextSize(label,cv2.FONT_HERSHEY_COMPLEX,1,5)\n",
    "        # print('labelSize>>',labelSize)\n",
    "        _x1 = x1\n",
    "        _y1 = y1#+int(labelSize[0][1]/2)\n",
    "        _x2 = _x1+labelSize[0][0]\n",
    "        _y2 = y1-int(labelSize[0][1])\n",
    "        cv2.rectangle(image,(_x1,_y1),(_x2,_y2),(0,255,0),cv2.FILLED)\n",
    "        cv2.putText(image,label,(x1,y1),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),2)\n",
    "        cv2.putText(image,str('%.2f' % (conf)),(x2,y2),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),2)\n",
    "#         df_list.append(df)\n",
    "#         fin_df = df_list\n",
    "#         fin_df = pd.concat(fin_df)\n",
    "#         print('fin_df',fin_df)\n",
    "        \n",
    "    return image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
